{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa46a136-a243-403c-96b7-a9c59503d7ab",
   "metadata": {},
   "source": [
    "Sources: \n",
    "https://python.langchain.com/v0.1/docs/langsmith/walkthrough/\n",
    "\n",
    "https://docs.smith.langchain.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecada74d-8820-4ebe-af80-013a229eb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from uuid import uuid4\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import bs4\n",
    "from langsmith import Client\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, load_tools\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, AgentType, initialize_agent, load_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith.evaluation import EvaluationResult\n",
    "from langsmith.schemas import Example, Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbbae78d-dd61-4a2a-a01b-886b24c50267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "unique_id = uuid4().hex[0:8]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b987ec49-5e08-4bb4-9af4-969052693e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "# Used by the agent in this tutorial\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8fb8bfe-c0e6-4f50-ab0f-c7064bfa72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "593923ae-5800-4296-9acc-6f914e5ca769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches the latest version of this prompt\n",
    "prompt = hub.pull(\"wfh/langsmith-agent-prompt:5d466cbc\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    DuckDuckGoSearchResults(\n",
    "        name=\"duck_duck_go\"\n",
    "    ),  # General internet search using DuckDuckGo\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e181af3e-93dd-4730-aac0-f2b0279f226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "runnable_agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=runnable_agent, tools=tools, handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20887ccc-d267-4804-9c8d-61c432cd4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    \"What is LangChain?\",\n",
    "    \"What's LangSmith?\",\n",
    "    \"When was Llama-v2 released?\",\n",
    "    \"What is the langsmith cookbook?\",\n",
    "    \"When did langchain first announce the hub?\",\n",
    "]\n",
    "\n",
    "results = agent_executor.batch([{\"input\": x} for x in inputs], return_exceptions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccf3b7b1-a3cf-49fb-a2a7-9bb13fbf0701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'What is LangChain?',\n",
       "  'output': 'I\\'m sorry, but I couldn\\'t find any information about \"LangChain\". Could you please provide more context or clarify your question?'},\n",
       " {'input': \"What's LangSmith?\",\n",
       "  'output': 'I\\'m sorry, but I couldn\\'t find any information about \"LangSmith\". It could be a company, a product, or a person. Can you provide more context or details about what you are referring to?'},\n",
       " {'input': 'When was Llama-v2 released?',\n",
       "  'output': 'Llama-v2 was released in July 2023.'},\n",
       " {'input': 'What is the langsmith cookbook?',\n",
       "  'output': 'The Langsmith Cookbook is a collection of recipes and cooking techniques created by Langsmith, a fictional character. It is a comprehensive guide that covers a wide range of cuisines and dishes, providing step-by-step instructions and tips for home cooks. The Langsmith Cookbook aims to inspire and empower individuals to explore their culinary creativity and enhance their cooking skills.'},\n",
       " {'input': 'When did langchain first announce the hub?',\n",
       "  'output': 'LangChain first announced the LangChain Hub on their blog on an unspecified date.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d5350-f6bb-431b-ad4e-ef0e6a2a9384",
   "metadata": {},
   "source": [
    "## Create a LangSmith dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba250136-7cfd-4670-a317-858369e78f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [\n",
    "    \"LangChain is an open-source framework for building applications using large language models. It is also the name of the company building LangSmith.\",\n",
    "    \"LangSmith is a unified platform for debugging, testing, and monitoring language model applications and agents powered by LangChain\",\n",
    "    \"July 18, 2023\",\n",
    "    \"The langsmith cookbook is a github repository containing detailed examples of how to use LangSmith to debug, evaluate, and monitor large language model-powered applications.\",\n",
    "    \"September 5, 2023\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f9c53e6-8bd2-420a-bc18-47440dc151fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithConflictError",
     "evalue": "Conflict for /datasets. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Dataset with this name already exists.\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/chatbot-langchain/lib/python3.10/site-packages/langsmith/utils.py:121\u001b[0m, in \u001b[0;36mraise_for_status_with_text\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot-langchain/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/chatbot-langchain/lib/python3.10/site-packages/langsmith/client.py:799\u001b[0m, in \u001b[0;36mClient.request_with_retries\u001b[0;34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    790\u001b[0m         method,\n\u001b[1;32m    791\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_kwargs,\n\u001b[1;32m    798\u001b[0m     )\n\u001b[0;32m--> 799\u001b[0m \u001b[43mls_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot-langchain/lib/python3.10/site-packages/langsmith/utils.py:123\u001b[0m, in \u001b[0;36mraise_for_status_with_text\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m.\u001b[39mtext) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHTTPError\u001b[0m: [Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLangSmithConflictError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent-qa\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAn example dataset of questions over the LangSmith documentation.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m client\u001b[38;5;241m.\u001b[39mcreate_examples(\n\u001b[1;32m      9\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: query} \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m inputs],\n\u001b[1;32m     10\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer} \u001b[38;5;28;01mfor\u001b[39;00m answer \u001b[38;5;129;01min\u001b[39;00m outputs],\n\u001b[1;32m     11\u001b[0m     dataset_id\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot-langchain/lib/python3.10/site-packages/langsmith/client.py:2422\u001b[0m, in \u001b[0;36mClient.create_dataset\u001b[0;34m(self, dataset_name, description, data_type)\u001b[0m\n\u001b[1;32m   2401\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a dataset in the LangSmith API.\u001b[39;00m\n\u001b[1;32m   2402\u001b[0m \n\u001b[1;32m   2403\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2415\u001b[0m \u001b[38;5;124;03m    The created dataset.\u001b[39;00m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2417\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ls_schemas\u001b[38;5;241m.\u001b[39mDatasetCreate(\n\u001b[1;32m   2418\u001b[0m     name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m   2419\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[1;32m   2420\u001b[0m     data_type\u001b[38;5;241m=\u001b[39mdata_type,\n\u001b[1;32m   2421\u001b[0m )\n\u001b[0;32m-> 2422\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2424\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/datasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContent-Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2427\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2428\u001b[0m ls_utils\u001b[38;5;241m.\u001b[39mraise_for_status_with_text(response)\n\u001b[1;32m   2429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ls_schemas\u001b[38;5;241m.\u001b[39mDataset(\n\u001b[1;32m   2430\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[1;32m   2431\u001b[0m     _host_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_host_url,\n\u001b[1;32m   2432\u001b[0m     _tenant_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_optional_tenant_id(),\n\u001b[1;32m   2433\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot-langchain/lib/python3.10/site-packages/langsmith/client.py:835\u001b[0m, in \u001b[0;36mClient.request_with_retries\u001b[0;34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils\u001b[38;5;241m.\u001b[39mLangSmithNotFoundError(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResource not found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils\u001b[38;5;241m.\u001b[39mLangSmithConflictError(\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConflict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    837\u001b[0m     )\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils\u001b[38;5;241m.\u001b[39mLangSmithError(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in LangSmith\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m     )\n",
      "\u001b[0;31mLangSmithConflictError\u001b[0m: Conflict for /datasets. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Dataset with this name already exists.\"}')"
     ]
    }
   ],
   "source": [
    "dataset_name = f\"agent-qa\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name,\n",
    "    description=\"An example dataset of questions over the LangSmith documentation.\",\n",
    ")\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"input\": query} for query in inputs],\n",
    "    outputs=[{\"output\": answer} for answer in outputs],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b730e04-d777-434b-be4a-09fb1adff1b9",
   "metadata": {},
   "source": [
    "## Initialize a new agent to benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91c41d28-eb1b-41ce-b067-72afaaf4a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since chains can be stateful (e.g. they can have memory), we provide\n",
    "# a way to initialize a new chain for each row in the dataset. This is done\n",
    "# by passing in a factory function that returns a new chain for each row.\n",
    "def create_agent(prompt, llm_with_tools):\n",
    "    runnable_agent = (\n",
    "        {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "                x[\"intermediate_steps\"]\n",
    "            ),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm_with_tools\n",
    "        | OpenAIToolsAgentOutputParser()\n",
    "    )\n",
    "    return AgentExecutor(agent=runnable_agent, tools=tools, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f888846b-54be-42ae-9854-006ff110e9ba",
   "metadata": {},
   "source": [
    "## Configure evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4162fa06-ef60-46c7-9018-40e77d900a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic Evaluatiors\n",
    "def check_not_idk(run: Run, example: Example):\n",
    "    \"\"\"Illustration of a custom evaluator.\"\"\"\n",
    "    agent_response = run.outputs[\"output\"]\n",
    "    if \"don't know\" in agent_response or \"not sure\" in agent_response:\n",
    "        score = 0\n",
    "    else:\n",
    "        score = 1\n",
    "    # You can access the dataset labels in example.outputs[key]\n",
    "    # You can also access the model inputs in run.inputs[key]\n",
    "    return EvaluationResult(\n",
    "        key=\"not_uncertain\",\n",
    "        score=score,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17058345-91c1-42c5-81ad-a47a0df7a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Evaluators such as Precision, Recall or AUC on the full \"test\"\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def max_pred_length(runs: List[Run], examples: List[Example]):\n",
    "    predictions = [len(run.outputs[\"output\"]) for run in runs]\n",
    "    return EvaluationResult(key=\"max_pred_length\", score=max(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5257804b-8738-41f8-9431-f41926846363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import EvaluatorType\n",
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    # Evaluators can either be an evaluator type (e.g., \"qa\", \"criteria\", \"embedding_distance\", etc.) or a configuration for that evaluator\n",
    "    evaluators=[\n",
    "        check_not_idk,\n",
    "        # Measures whether a QA response is \"Correct\", based on a reference answer\n",
    "        # You can also select via the raw string \"qa\"\n",
    "        EvaluatorType.QA,\n",
    "        # Measure the embedding distance between the output and the reference answer\n",
    "        # Equivalent to: EvalConfig.EmbeddingDistance(embeddings=OpenAIEmbeddings())\n",
    "        EvaluatorType.EMBEDDING_DISTANCE,\n",
    "        # Grade whether the output satisfies the stated criteria.\n",
    "        # You can select a default one such as \"helpfulness\" or provide your own.\n",
    "        RunEvalConfig.LabeledCriteria(\"helpfulness\"),\n",
    "        # The LabeledScoreString evaluator outputs a score on a scale from 1-10.\n",
    "        # You can use default criteria or write our own rubric\n",
    "        RunEvalConfig.LabeledScoreString(\n",
    "            {\n",
    "                \"accuracy\": \"\"\"\n",
    "Score 1: The answer is completely unrelated to the reference.\n",
    "Score 3: The answer has minor relevance but does not align with the reference.\n",
    "Score 5: The answer has moderate relevance but contains inaccuracies.\n",
    "Score 7: The answer aligns with the reference but has minor errors or omissions.\n",
    "Score 10: The answer is completely accurate and aligns perfectly with the reference.\"\"\"\n",
    "            },\n",
    "            normalize_by=10,\n",
    "        ),\n",
    "    ],\n",
    "    batch_evaluators=[max_pred_length],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83299233-0378-44ce-9eee-352f433ea9ef",
   "metadata": {},
   "source": [
    "## Run the agent and evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131ca67-421a-4b39-9cbf-5de8047d3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# We will test this version of the prompt\n",
    "prompt = hub.pull(\"wfh/langsmith-agent-prompt:798e7324\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8835b-b311-4c53-9732-c76e4c130c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from langchain.smith import arun_on_dataset, run_on_dataset\n",
    "\n",
    "chain_results = run_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=functools.partial(\n",
    "        create_agent, prompt=prompt, llm_with_tools=llm_with_tools\n",
    "    ),\n",
    "    evaluation=evaluation_config,\n",
    "    verbose=True,\n",
    "    client=client,\n",
    "    project_name=f\"tools-agent-test-5d466cbc-{unique_id}\",\n",
    "    # Project metadata communicates the experiment parameters,\n",
    "    # Useful for reviewing the test results\n",
    "    project_metadata={\n",
    "        \"env\": \"testing-notebook\",\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"prompt\": \"5d466cbc\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Sometimes, the agent will error due to parsing issues, incompatible tool inputs, etc.\n",
    "# These are logged as warnings here and captured as errors in the tracing UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e21da0-ddd6-4bd3-a1f6-4dd14c2739aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.list_runs(project_name=chain_results[\"project_name\"], execution_order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e4622-41e6-4a62-961d-39f32fb6ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resulting tests are stored in a project.  You can programmatically\n",
    "# access important metadata from the test, such as the dataset version it was run on\n",
    "# or your application's revision ID.\n",
    "client.read_project(project_name=chain_results[\"project_name\"]).metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529282b3-6961-43aa-8fda-b6636ed23e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After some time, the test metrics will be populated as well.\n",
    "client.read_project(project_name=chain_results[\"project_name\"]).feedback_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d434c9-00aa-441e-8933-2785bf80975e",
   "metadata": {},
   "source": [
    "## Another evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b6ad9a4-ae56-47af-83f4-450a453954c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.tools \n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05585a61-2dbe-4a49-a1c6-4abcfd4c7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "tools = load_tools(['llm-math'], llm =llm)\n",
    "llm_with_tools = llm.bind_functions([ langchain.tools.format_tool_to_openai_function(t) for t in tools])\n",
    "\n",
    "prompt = hub.pull(\"wfh/langsmith-agent-prompt:5d466cbc\")\n",
    "\n",
    "def format_scratchpad(x: dict) -> str:\n",
    "    return format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "\n",
    "def get_chat_history(x: dict) -> list:\n",
    "    return x.get(\"chat_history\", [])\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": itemgetter(\"input\"),\n",
    "        \"agent_scratchpad\": format_scratchpad,\n",
    "        \"chat_history\": get_chat_history,\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ").with_config(run_name=\"Agent\")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent = agent,\n",
    "    tools = tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf4c9aa3-3568-49da-b352-d344663f9a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandragross/miniconda3/envs/chatbot-langchain/lib/python3.10/site-packages/langchain/smith/evaluation/runner_utils.py:1356: LangChainPendingDeprecationWarning: The tags argument is deprecated and will be removed in a future release. Please specify project_metadata instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'test-agent-qa-2' at:\n",
      "https://smith.langchain.com/o/ea48c7ea-265e-53a0-8dc0-75e0b69eccff/datasets/f4b028d5-5d96-48e7-becc-2927e164370e/compare?selectedSessions=7bd4c82c-3c17-444a-aa8a-02bb9f2d0cc5\n",
      "\n",
      "View all tests for Dataset agent-qa at:\n",
      "https://smith.langchain.com/o/ea48c7ea-265e-53a0-8dc0-75e0b69eccff/datasets/f4b028d5-5d96-48e7-becc-2927e164370e\n",
      "[------------------------------------------------->] 5/5"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.COT Contextual Accuracy</th>\n",
       "      <th>feedback.insensitivity</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a31ff984-7c76-4293-bf5d-2918360f0be2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.359858</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.257507</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.941417</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.301709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.432910</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.559530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.563722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.COT Contextual Accuracy  feedback.insensitivity  \\\n",
       "count                                5.0                     5.0   \n",
       "unique                               NaN                     NaN   \n",
       "top                                  NaN                     NaN   \n",
       "freq                                 NaN                     NaN   \n",
       "mean                                 0.0                     0.0   \n",
       "std                                  0.0                     0.0   \n",
       "min                                  0.0                     0.0   \n",
       "25%                                  0.0                     0.0   \n",
       "50%                                  0.0                     0.0   \n",
       "75%                                  0.0                     0.0   \n",
       "max                                  0.0                     0.0   \n",
       "\n",
       "        feedback.helpfulness error  execution_time  \\\n",
       "count                    5.0     0        5.000000   \n",
       "unique                   NaN     0             NaN   \n",
       "top                      NaN   NaN             NaN   \n",
       "freq                     NaN   NaN             NaN   \n",
       "mean                     0.0   NaN        1.359858   \n",
       "std                      0.0   NaN        0.257507   \n",
       "min                      0.0   NaN        0.941417   \n",
       "25%                      0.0   NaN        1.301709   \n",
       "50%                      0.0   NaN        1.432910   \n",
       "75%                      0.0   NaN        1.559530   \n",
       "max                      0.0   NaN        1.563722   \n",
       "\n",
       "                                      run_id  \n",
       "count                                      5  \n",
       "unique                                     5  \n",
       "top     a31ff984-7c76-4293-bf5d-2918360f0be2  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        \"cot_qa\",\n",
    "        RunEvalConfig.LabeledCriteria(\"insensitivity\"),\n",
    "        RunEvalConfig.LabeledCriteria(\"helpfulness\")\n",
    "    ],\n",
    "    custom_evaluators=[],\n",
    "    eval_llm=ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    ")\n",
    "\n",
    "client = Client()\n",
    "chain_results = client.run_on_dataset(\n",
    "    dataset_name=\"agent-qa\",\n",
    "    llm_or_chain_factory=agent_executor,\n",
    "    evaluation=eval_config,\n",
    "    project_name=\"test-agent-qa-2\",\n",
    "    concurrency_level=5,\n",
    "    verbose=True,\n",
    "    tags=[\"gpt-3.5\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6e20a-cf83-46a0-8eae-fa5ca227964e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eff642-ec1b-4020-8e36-b06b2903e228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chatbot-langchain]",
   "language": "python",
   "name": "conda-env-chatbot-langchain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
